---
title: "Protocol for FlowSOM implementation"
output: html_notebook
---

NOTE: *R version 4.5.0*. Also make sure [Rtools45](https://cran.r-project.org/bin/windows/Rtools/rtools45/rtools.html) is downloaded.

## STEP 0.1: DOWNLOADING PACKAGES (SKIP IF ALREADY DOWNLOADED)

Navigate towards 'Tools \> Install Packages' and download the following packages:

1.  *ggplot2*
2.  *ggpubr*
3.  *pheatmap*
4.  *tidyr*
5.  *devtools*

Then go on to download *BioConductor* in the following way in order to download *FlowCore* correctly.

```{r}
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

#The following initializes usage of Bioc devel
BiocManager::install(version='devel')
BiocManager::install("flowCore", force = TRUE)
BiocManager::install("flowAI")
BiocManager::install("ggcyto")
BiocManager::install("openCyto")

#use devtools to download packages from github
devtools::install_github("saeyslab/PeacoQC", force=TRUE)
devtools::install_github("saeyslab/FlowSOM")
```

## STEP 1: PREPROCESSING: STANDARDIZATION + TRANSFORMATION STEPS.

The code below selects the patient files based on their patient_id from the .LMD files. The .LMD files contain two versions of .fcs files: Version 3.0 or Version 2.0. In the code below version 3.0 is selected as these contain the spill over matrices for compensation.

*NOTE: preprocessing full dataset can be quite loaded for CPU, better to preprocess in batches.*

```{r}
library('flowCore') 
library('ggplot2')
library('flowAI')
library('readxl')
library('ggcyto')
library('openCyto')
library('flowClust')
```

```{r}
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, 
                      message = FALSE, cache.lazy = FALSE)

fcs_dir <- "D:/Internship/data/full dataset/"

#parsing filenames and setting up patient dictionary
original_ds <- list.files(path=fcs_dir, pattern= '\\.LMD$', full.names=FALSE)
patient_ids <- as.integer(sub(".*[^0-9](\\d+)\\s+tube.*", "\\1", original_ds))
patient_file_dict <- split(original_ds, patient_ids)

#select which patients you want to extract: AML, MDS, healthy or full dataset
#aml_patients = c(144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 196, 197, 198, 199, 201)

#mds_patients = c(103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 186, 187, 188, 189, 192, 195, 200, 202, 204, 205, 206, 207, 208, 209, 210, 211)

healthy_patients = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,49,50)

#full_dataset = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,49,50,103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 186, 187, 188, 189, 192, 195, 200, 202, 204, 205, 206, 207, 208, 209, 210, 211, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 196, 197, 198, 199, 201)

if (exists("aml_patients")) {
  selected_patients <- aml_patients
} else if (exists("mds_patients")) {
  selected_patients <- mds_patients
} else if (exists("healthy_patients")) {
  selected_patients <- healthy_patients
} else if (exists("full_dataset")) {
  selected_patients <- full_dataset
} else {
  stop("No patient group was defined.")
}


fcs_files <- unlist(patient_file_dict[as.character(selected_patients)])
fcs_data_list <- list()

for (id in names(patient_file_dict)) {
  if (as.integer(id) %in% selected_patients) {
    file_names <- patient_file_dict[[id]]
    
    for (file in file_names) {
      file_path <- file.path(fcs_dir, file)
      key <- tools::file_path_sans_ext(file)
      
      dataset_index <- NULL
      
      for (i in 1:2) {
        tryCatch({
          ff_try <- suppressWarnings(read.FCS(file_path, dataset = i))
          
          version_keys <- grep("version", names(ff_try@description), ignore.case = TRUE, value = TRUE)
          
          if (length(version_keys) > 0) {
            fcs_version <- ff_try@description[[version_keys[1]]]
            
            if (grepl("^3(\\.0)?$", fcs_version)) {
              fcs_data_list[[key]] <- ff_try
              dataset_index <- i
              break
            }
          }
        }, error = function(e) {})
      }
      
      if (is.null(dataset_index)) {
        warning(paste("FCS version 3.0 not found for file:", file))
      }
    }
  }
}
```

### STEP 1.1: COLUMN NAME STANDARDIZATION

While reading the files, it was observed that column names were not consistent across files. They appeared in two different formats:

```         
[1] "FS-H"   "FS-A"   "SS-H"   "SS-A"   "FL1-A"  "FL2-A"  "FL3-A"  "FL4-A"  "FL5-A"  "FL6-A"  "FL7-A"  "FL8-A"  "FL9-A"  "FL10-A" "TIME" 
```

```         
 [1] "FS INT LIN"   "SS INT LIN"   "FL1 INT LOG"  "FL2 INT LOG"  "FL3 INT LOG"  "FL4 INT LOG"  "FL5 INT LOG"  "FL6 INT LOG"  "FL7 INT LOG"  [10] "FL8 INT LOG"  "FL9 INT LOG"  "FL10 INT LOG" "TIME"         "FS PEAK LIN"  "SS PEAK LIN" 
```

The column names have been standardized to a consistent format to ensure reliable access during bulk preprocessing.

```{r}
#CHECKING COLUMN NAMES BEFORE NAME STANDARDIZATION
fs0 <- fcs_data_list[[1]]
colnames(fs0)
```

```{r}
#STANDARDIZING COLUMNNAMES
rename_common_channels <- function(ff) {
  standard_names <- c("FITC", "PE", "ECD", "PC5.5", "PC7", 
                      "APC", "A700", "A750", "HLA", "KO")
  
  old_names <- colnames(ff)
  new_names <- old_names
  
  #Rename fluorochrome channels
  for (i in seq_along(standard_names)) {
    pattern <- paste0("^FL", i, "([ -].*)?$")
    matched_idx <- grep(pattern, old_names, ignore.case = TRUE)
    
    if (length(matched_idx) > 0) {
      new_names[matched_idx[1]] <- standard_names[i]
    }
  }
  
  #Rename scatter channels
  scatter_renames <- list(
    "FS INT LIN"   = "FS-A",
    "FS PEAK LIN"  = "FS-H",
    "SS INT LIN"   = "SS-A",
    "SS PEAK LIN"  = "SS-H"
  )
  
  for (original in names(scatter_renames)) {
    idx <- which(old_names == original)
    if (length(idx) > 0) {
      new_names[idx] <- scatter_renames[[original]]
    }
  }

  colnames(ff@exprs) <- new_names
  colnames(ff) <- new_names
  
  return(ff)
}

renamed_fcs_list <- lapply(fcs_data_list, rename_common_channels)
```

```{r}
#CHECKING COLUMN NAMES AFTER STANDARDIZATION
fs1 <- renamed_fcs_list[[1]]
colnames(fs1)
```

### STEP 1.2: COMPENSATION

Compensation can be done automatically or manually. For this, a **Spillover Spreading Matrix** **(SSM)** is used to correct for the overlap of fluorescent signals between different channels. It is a crucial step as it corrects for fluorescence spillover, where the emission of one fluorochrome is detected in a channel designed for another.

For the new flow cytometer; when using a FCS 2.0 version file, no manual compensation needs to be implemented. For the FCS 3.0 version, manual compensation can be performed by accessing the spillover matrix through `spillover(ff)` and perform compensation by `` compensate(ff, spillover(ff)$`$SPILLOVER`) ``. It is also possible to import the spillover matrix from an excel file and implement it using `compensate(ff, excel_matrix)`

For old flow cytometer; For both versions, no spillover matrices are saved in the .fcs because default compensation matrix from the machine is used. So no manual compensation needs to be performed.

*NOTE: make sure compensation matrix is in fractions and NOT percentages!!*

PS. Columns sometimes contain for FL-7, both the area and width. In the spillover matrix, these two have identical values, resulting in a singular matrix and making it unable to be inverted. This row was therefore removed and these files were then processed.

PPS. In cases where tubes other than Tube 1 do not contain a valid spillover matrix, a reference sample is selected from which the spillover matrix is applied. This ensures proper compensation when the original `.fsc` file lacks a correctly stored matrix.

```{r}
#CHECKING RAW DATA
ff_raw <- renamed_fcs_list[[2]]
df_raw <- as.data.frame(exprs(ff_raw))
```

```{r}
#COMPENSATION
reference_spillovers <- list(
  "tube 2" = "Femoral head 2 tube 2",
  "tube 3" = "Femoral head 2 tube 3",
  "tube 4" = "Femoral head 2 tube 4",
  "tube 5" = "Femoral head 2 tube 5",
  "tube 6" = "Femoral head 2 tube 6",
  "tube 7" = "Femoral head 2 tube 7"
)

compensate_ff <- function(ff, filename = NULL, fcs_files = NULL, reference_spillovers = NULL) {
  #skip Tube 1
  if (grepl("tube 1", filename, ignore.case = TRUE)) {
    message("Skipping Tube 1: ", filename)
    return(ff)
  }
  
  #selecting SSM, otherwise selecting reference SSM
  spill <- tryCatch(spillover(ff)[["$SPILLOVER"]], error = function(e) NULL)
  if (is.null(spill)) {
    tube_label <- sub(".*(tube \\d+).*", "\\1", filename, ignore.case = TRUE)
    tube_label <- trimws(tube_label)
    ref_name <- reference_spillovers[[tube_label]]

    
    if (!is.null(ref_name) && ref_name %in% names(fcs_files)) {
      ref_ff <- fcs_files[[ref_name]]
      spill <- tryCatch(spillover(ref_ff)[["$SPILLOVER"]], error = function(e) NULL)
      message("Using reference spillover from: ", ref_name, " for ", filename)
    }
    
    if (is.null(spill)) {
      warning("No spillover matrix found for: ", filename)
      keyword(ff)[["$TIMESTEP"]] <- 0.000286
      return(ff)
    }
  }
  
  #selecting appropriate channels
  exclude_channels <- c("FS-A", "FS-H", "SS-A", "SS-H", "TIME", "FS TOF LIN", "SS TOF LIN","FL7 INT LIN", "FL7 TOF LIN")
  fluor_channels <- setdiff(colnames(ff), exclude_channels)
  
  colnames(spill) <- fluor_channels
  rownames(spill) <- fluor_channels
  
  spill_filtered <- spill[setdiff(fluor_channels, "FL7-W"), setdiff(fluor_channels, "FL7-W")]
  
  ff_comp <- compensate(ff, spill_filtered)
  keyword(ff_comp)[["$TIMESTEP"]] <- 0.000286

  return(ff_comp)
}

fcs_compensated <- Map(function(ff, name) {
  compensate_ff(ff, filename = name, fcs_files = renamed_fcs_list, reference_spillovers = reference_spillovers)
}, renamed_fcs_list, names(renamed_fcs_list))
```

```{r}
#CHECKING COMPENSATED DATA
ff_comp <- fcs_compensated[[2]]
df_comp <- as.data.frame(exprs(ff_comp))
```

### STEP 1.3 - Quality Check using flowAI

flowAI is used to remove events having anomalous values when looking at three aspect of a flow cytometry analysis:

1.  **flow rate**: Checks whether cells are passing through the flow cytometer at an appropriate rate. Anomalies could be due to clumping of cells, clogging or incorrect flow rate settings. A high percentages suggests that cells may be analyzed under suboptimal flow conditions.

    -   This step uses *generalized ESD* to detect outliers. See [this link](https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h3.htm) for further explanation of this test.

2.  **signal acquisition**: accounts for fluorescence and scatter signal of cells. Anomalies can arise due to inadequate staining, photobleaching etc. A substantial proportion of cells with anomalous signal acquisition can lead to inaccurate fluorescence intensity measurements, affecting the interpretation of the data.

    -   Uses *Binary Segmentation* to check for changepoints and remove instable regions

3.  **dynamic range**: Evaluates whether intensities of cells fall within detectable range of cytometer. Cells outside this range can either be too dim (below detection limit) or too bright (causing signal saturation), both of which can skew data interpretation.

    -   Filter out all measurements above hard upper limit and removes all negative scatter values. For fluorescent channels, it removed outliers of negative range.

Several arguments can be changed within `flow_auto_qc` to improve quality control results. Moreover, `remove_from` can be used to perform partial quality control on only one or two of the above mentioned properties.

The suggestion is to run automatic method first with default settings, if results are not satisfying, we can modify arguments.

*NOTE: TIMESTEP IS NOT PRESENT IN .fcs FILE. In [NAVIOS TETRA MANUAL](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://4.imimg.com/data4/MJ/IL/MY-4372999/navios-flow-cytometer.pdf), the TIME parameter reflects the timing of each event as unitless integers representing time bins, rather than actual seconds. To convert these values into real-time units, TIMESTEP must be applied as scaling factor.*

*For Navios cytometer, TIME channel spans 1,048,576 bins (2²⁰) over a default acquisition period of 300 seconds. Therefore, each TIME unit corresponds to approximately 0.000286 seconds (300 ÷ 1,048,576). Multiplying TIME values by this TIMESTEP converts them into meaningful timestamps, enabling proper time-based quality control and analysis.*

```{r}
#AUTOMATIC QUALITY CONTROL USING FLOWAI
fcs_cleaned <- list()

for (i in seq_along(fcs_compensated)) {
  file_name <- names(fcs_compensated)[i]
  ff <- fcs_compensated[[i]]
  proceed_flag <- TRUE
  
  tryCatch({
    cleaned_fcs_data <- flow_auto_qc(ff)  # Pass flowFrame directly
  }, error = function(e) {
    cat("Error in flow_auto_qc for", file_name, ":", as.character(e$message), "\n")
    proceed_flag <- FALSE
  })

  if (proceed_flag) {
    fcs_cleaned[[file_name]] <- cleaned_fcs_data
    cat("Cleaned:", file_name, "\n")
  }
}
```

```{r}
#CHECKING CLEANED DATA
ff_cleaned <- fcs_cleaned[[1]]
df_cleaned <- as.data.frame(exprs(ff_cleaned))
```

### STEP 1.4 - TRANSFORMATION

Compensation corrects for spectral overlap between fluorochromes but does not address the underlying distribution of flow cytometry data. Such data typically exhibits a positively skewed distribution, especially in fluorescent channels. To make the data more suitable for analysis and visualization, transformation methods—such as logarithmic, biexponential (logicle), or arcsinh—are applied to achieve a more symmetric, near-normal distribution.

In this workflow, an **arcsinh transformation** is applied to the data, followed by **min–max normalization**, in alignment with the methodology described by Duetz et al. (2021).

```{r}
#ARCSINH TRANSFORMATION
arcsinh_transform <- function(ff, cofactor = 150, exclude_channels = c("FS-A", "FS-H", "SS-A", "SS-H", "TIME")) {
  transform_channels <- setdiff(colnames(exprs(ff)), exclude_channels)
  
  arcsinh_tf <- transformList(
    transform_channels,
    arcsinhTransform(a = 0, b = 1 / cofactor, c = 0)
  )

  ff_transformed <- transform(ff, arcsinh_tf)
  
  return(ff_transformed)
}

fcs_transformed <- lapply(fcs_cleaned, arcsinh_transform, cofactor = 150)
```

```{r}
#CHECKING TRANSFORMED DATA
ff_trans <- fcs_transformed[[2]]

# Convert to a data frame
df_trans <- as.data.frame(exprs(ff_trans))
```

```{r}
autoplot(ff_trans, x = "KO", y = "SS-A", bins = 200)
```

```{r}
#MIN-MAX NORMALIZATION
min_max_quantile_normalize <- function(ff, exclude_channels = c("FS-A", "FS-H", "SS-A", "SS-H", "TIME")) {
  expr <- exprs(ff)
  
  norm_channels <- setdiff(colnames(expr), exclude_channels)
  
  expr[, norm_channels] <- apply(expr[, norm_channels, drop = FALSE], 2, function(x) {
    (x - quantile(x, 0.001, na.rm = TRUE)) / 
      (quantile(x, 0.999, na.rm = TRUE) - quantile(x, 0.001, na.rm = TRUE))
  })
  
  flowCore::exprs(ff) <- expr
  return(ff)
}

fcs_norm <- vector("list", length(fcs_transformed))
names(fcs_norm) <- names(fcs_transformed)

for (i in seq_along(fcs_transformed)) {
  cat("Normalizing flowFrame", i, "of", length(fcs_transformed), "\n")
  fcs_norm[[i]] <- min_max_quantile_normalize(fcs_transformed[[i]])
}
```

```{r}
#CHECKING TRANSFORMED DATA
ff_norm <- fcs_norm[[2]]

# Convert to a data frame
df_norm <- as.data.frame(exprs(ff_norm))
```

```{r}
autoplot(ff_norm, x = "KO", y = "SS-A", bins = 200)
```

### STEP 1.5: SAVING STANDARDIZED AND TRANSFORMED DATA FILES on DRIVE

```{r}
output_dir <- normalizePath("D:/Internship/data/transformed full dataset", mustWork = FALSE)
dir.create(output_dir, showWarnings = FALSE)

for (file_name in names(fcs_norm)) {
  file_path <- file.path(output_dir, paste0(file_name, ".fcs"))
  write.FCS(fcs_norm[[file_name]], filename = file_path)
}
```

## STEP 2: REMOVAL OF UNWANTED EVENTS

### STEP 2.1 - loading in libraries and files we want to clean up

```{r}
library('flowCore') 
library('ggplot2')
library('flowAI')
library('readxl')
library('ggcyto')
library('openCyto')
library('flowClust')
```

```{r}
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, 
                      message = FALSE, cache.lazy = FALSE)

fcs_dir <- "D:/Internship/data/transformed full dataset/"

#parsing filenames and setting up patient dictionary
original_ds <- list.files(path=fcs_dir, pattern= '\\.fcs$', full.names=FALSE)
patient_ids <- as.integer(sub(".*[^0-9](\\d+)\\s+tube.*", "\\1", original_ds))
patient_file_dict <- split(original_ds, patient_ids)

#select which patients you want to extract: AML, MDS, healthy or fulldataset

#aml_patients = c(144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 196, 197, 198, 199, 201)

#mds_patients = c(103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 186, 187, 188, 189, 192, 195, 200, 202, 204, 205, 206, 207, 208, 209, 210, 211)

healthy_patients = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,49,50)

#full_dataset = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,49,50,103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 186, 187, 188, 189, 192, 195, 200, 202, 204, 205, 206, 207, 208, 209, 210, 211, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 196, 197, 198, 199, 201)

if (exists("aml_patients")) {
  selected_patients <- aml_patients
} else if (exists("mds_patients")) {
  selected_patients <- mds_patients
} else if (exists("healthy_patients")) {
  selected_patients <- healthy_patients
} else if (exists("full_dataset")) {
  selected_patients <- full_dataset
} else {
  stop("No patient group was defined.")
}

fcs_file_names <- unlist(patient_file_dict[as.character(selected_patients)])
fcs_paths <- file.path(fcs_dir, fcs_file_names)

fcs_files <- setNames(lapply(fcs_paths, read.FCS, transformation = FALSE), fcs_file_names)
```

### STEP 2.2 - Gating out scatter outliers

In order to gate out debris, the function `flowClust.2d` is employed. This performs automated gating by applying model-based clustering FS-A and SS-A channels. It uses the `flowClust` algorithm, which fits a mixture of multivariate t-distributions to the selected channels, modeling the data as a combination of distinct cell populations (clusters).

In this case 2 clusters are chosen, one for debris and the other for cells. `flowClust.2d` then identifies the main cluster of interest (usually the largest or most biologically relevant cluster) based on membership probabilities. It converts this cluster's boundary into a polygon gate using the `clust2Poly` function, which defines the spatial region of this population in the 2D parameter space.

This approach provides a statistically rigorous, unsupervised way to separate cell populations from debris or outliers based on scatter properties, allowing for consistent and reproducible gating prior to downstream analysis.

```{r}
ff_raw <- fcs_files[[2]]
df_raw <- as.data.frame(exprs(ff_raw))
```

```{r}
my_gates <- lapply(seq_along(fcs_files), function(i) {
  cat("Processing sample", i, "of", length(fcs_files), "\n")
  
  ff <- fcs_files[[i]]
  
  # Extract the two channels for clustering
  ch_data <- exprs(ff)[, c("FS-A", "SS-A")]
  
  # Check for valid, non-empty, non-NA data
  if (nrow(ch_data) == 0 || all(is.na(ch_data))) {
    warning(paste("Sample", i, "is empty after gating. Skipping."))
    return(NULL)
  }

  if (nrow(na.omit(ch_data)) < 10) {
    warning(paste("Sample", i, "has too few events after gating. Skipping."))
    return(NULL)
  }
  
  # Call clustering only if data is valid
  openCyto:::.flowClust.2d(ff, channels = c("FS-A", "SS-A"), K = 2)
})
```

```{r}
fcs_gated <- mapply(Subset, fcs_files, my_gates, SIMPLIFY = FALSE)
```

```{r}
#CHECKING GATED DATA
ff_gated <- fcs_gated[[2]]
df_gated <- as.data.frame(exprs(ff_gated))
```

### STEP 2.3 - Removing doublets

We can use a developed R code section from the Duetz et al. (2021) paper to remove doublets from the data

```{r}
is_single <- function(ff, plot = FALSE, ...) {
  fsc_a <- flowCore::exprs(ff)[,"FS-A"]
  fsc_h <- flowCore::exprs(ff)[,"FS-H"]
  
  bins <- cut(fsc_a, 10)
  
  ratios <- fsc_h / fsc_a
  slope_per_bin <- tapply(ratios, bins, mean)
  expected_values <- fsc_a * slope_per_bin[bins]
  deviations <- abs(fsc_h - expected_values)
  
  x <- tapply(fsc_a, bins, mean)
  e <- tapply(expected_values, bins, mean)
  d <- tapply(deviations, bins, function(x){mean(x) + 2*sd(x)})
  y <- e - d
  
  spl <- splinefun(x, y)
  
  if (plot) {
    flowDensity::plotDens(ff, c("FS-A", "FS-H"), ...)
    points(x, e, col = "red", pch = 19)
    points(x, y, col = "red", pch = 19)
    lines(seq(1, 300000, by = 1000), 
          spl(seq(1, 300000, by = 1000)),
          col = "red",
          lwd = 2)
  }

  selection <- fsc_h > spl(fsc_a)
  return(selection)
}

single_cells_list <- vector("list", length(fcs_gated))
names(single_cells_list) <- names(fcs_gated)

for (i in seq_along(fcs_gated)) {
  cat(sprintf("Processing sample %d of %d: %s\n", i, length(fcs_gated), names(fcs_gated)[i]))
  single_cells_list[[i]] <- is_single(fcs_gated[[i]], plot = FALSE)
}

fcs_singles <- mapply(function(ff, sel) {
  ff[sel, ]  # keep rows where sel == TRUE
}, fcs_gated, single_cells_list, SIMPLIFY = FALSE)
```

```{r}
#INSPECTING DOUBLET REMOVED DATA
ff_single <- fcs_singles[[2]]
df_single <- as.data.frame(exprs(ff_single))
```

```{r}
autoplot(ff_single, x = "KO", y = "SS-A", bins = 200)
```

### STEP 2.4 - Saving preprocessed files

```{r}
library(flowCore)

#output folder
out_dir <- "D:/Internship/data/preprocessed dataset"
dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)

for (name in names(fcs_singles)) {
  ff <- fcs_singles[[name]]
  filename <- file.path(out_dir, paste0(tools::file_path_sans_ext(name), "_prepro.fcs"))
  write.FCS(ff, filename)
  cat("Saved:", filename, "\n")
}
```

### STEP 2.5 - VISUALISATION of preprocessing pipeline

```{r}
library(flowCore)
library(ggplot2)

#which .fcs file do you want to visualize?
raw_ff <- read.FCS("D:/Internship/data/renamed full dataset/Femoral head 1 tube 2.fcs", transformation = FALSE)
preprocessed_ff <- read.FCS("D:/Internship/data/preprocessed dataset/Femoral head 1 tube 2_prepro.fcs", transformation = FALSE)

#which columns do you want to visualize?
col_to_visualize <- c("FS-H", "FS-A", "SS-A", "KO")

raw_expr <- exprs(raw_ff)
pre_expr <- exprs(preprocessed_ff)


rounded_raw <- as.data.frame(round(raw_expr[, col_to_visualize], 3))
rounded_pre <- as.data.frame(round(pre_expr[, col_to_visualize], 3))

rounded_raw$Status <- "Removed"

kept <- semi_join(rounded_raw, rounded_pre, by = c("FS-H", "FS-A"))

kept$Status <- "Kept"

removed <- anti_join(rounded_raw, kept, by = c("FS-H", "FS-A"))

plot_df <- rbind(kept, removed)

#Adapt x, y, axis names, and title to plot you want to make
ggplot(plot_df, aes(x = `KO`, y = `SS-A`, color = Status)) +
  geom_point(size = 0.5, alpha = 0.6) +
  scale_color_manual(values = c("Kept" = "blue", "Removed" = "red")) +
  theme_minimal() +
  labs(title = "After preprocessing: KO vs. SSC-A", x = "CD45", y = "SSC-A")

```

```{r}
colnames(preprocessed_ff)
```

```{r}


```

## STEP 3: APPLYING FLOWSOM

wdhiuehdud

```{r}
#FlowSOM fuction
names(flow_frame)
fSOM <- FlowSOM(flow_frame, compensate = FALSE, transform = FALSE, 
                toTransform = c(4:16), 
                scale = TRUE,
                colsToUse = c(4, 5, 7, 8, 10, 11, 12), xdim = 6, ydim = 6, nClus = 8,
                seed = 42, rlen = 140)
?FlowSOM
?BuildMST
#Building the selforganizing map
fSOM <- BuildSOM(fSOM, c(4, 5, 7, 8, 10, 11, 12), xdim = 6, ydim = 
                   6, rlen = 140)
str(fSOM$map, max.level = 2)

#Building the minimal spanning tree
fSOM <- BuildMST(fSOM, tSNE= FALSE)
str(fSOM$MST)

#Plot the graph
PlotStars(fSOM, backgroundValues = fSOM$metaclustering, equalNodeSize = TRUE)
?PlotStars
PlotNumbers(fSOM,maxNodeSize = 0.4,equalNodeSize = TRUE)

Plot2DScatters(fSOM, channelpairs = list(c("V500-C-A", "SSC-A")), 
               metaclusters = c(1,2,3,4,5), 
               plotFile = "ps+pmma, NR & Ritdye (rlen = 140, xy =100).png", 
               density = FALSE, 
               centers = FALSE)

#FlowSOM Report
FlowSOMmary(fSOM, plotFile = "FlowSOM pmma + ps (No NR).pdf")


test <- as.data.frame(flow_frame@exprs)
test$`V500-C-A`
fig <- plot_ly(test, x = ~`PE-A`, y = ~`SSC-A`, z = ~`V500-C-A`, type = "scatter3d",
               size = 0.01)

fig
```
